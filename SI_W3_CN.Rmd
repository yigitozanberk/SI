---
title: "Statistical Inference Week 3 Class Notes"
author: "Yigit Ozan Berk"
date: "6/18/2019"
output: html_document
---

# Lectures
https://github.com/DataScienceSpecialization/courses/

- T confidence intervals
- T confidence intervals example
- Independent group T intervals
- A note on unequal variance

Further reading on p values
statistical evidence: a likelihood paradigm - by richard royall
toward evidence-based medical statistics. 1:the p value fallcy - by steve goodman
the earth is round(p <.05) - by cohen




# T confidence intervals

T interval is for small sample sizes.

If in doubt, use T interval, because as the sample size increases, T interval will become more and more like the Z interval(all distributions in previous lectures) anyway.

T distribution was invented by William Gosset(under the pseudonym 'student')

T distribution has only one parameter = degrees of freedom.
## T distribution works well whenever the distribution of the data is roughly symmetric and mound shaped

paired observations are often analyzed using the t interval by taking differences

t interval converges to the same interval as the CLT yielded.

for skewed distributions, the spirit of the t interval assumptions are violated
- you can use the log scale, which often take care of the skewness of the data, or you can use other procedures. for example creating bootstrap conficdence intervals

for highly discrete data, other distributions are available


# Example - sleep data

```{r}
data(sleep)
head(sleep)
#extra hours slept, group ID, and subject ID
```

**check out the rmarkdown file for the nice plot here**

```{r}
#first 10 measurements
g1 <- sleep$extra[1:10]
g2 <- sleep$extra[11:20]
difference <- g2 - g1
mn <- mean(difference)
s <- sd(difference)
n <- 10

mn + c(-1, 1)*qt(.975, n-1)*s/sqrt(n)
#similarly written in different forms as follows:

```

```{r}
t.test(difference)

```


```{r}
t.test(g2, g1, paired = TRUE)

```

```{r}
t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)
#outcome extra is a function of the group, where paired equals true, evaluated from the data sleep
```


# Independent group t confidence intervals

A-B testing or randomized trial, test group and placebo group sistemi demek.

done in order to balance unobserved co-variates that may contaminate results

we can't use the paired t test because the groups are independent.

```{r}
#mistakenly treating the sleep data as group

n1 <- length(g1)
n2 <- length(g2)
sp <- sqrt(((n1-1)* sd(g1)^2 + (n2 - 1)*sd(g2)^2) / (n1 + n2 - 2))
md <- mean(g2) - mean(g1)
semd <- sp*sqrt(1/n1 + 1/n2)
rbind(
        md + c(-1 , 1) * qt(.975, n1+n2 - 2)*semd,
        t.test(g2, g1, paired = FALSE, var.equal= TRUE)$conf,
        #for this to work, the dataset needs to have only two levels.
        t.test(g2, g1, paired = TRUE)$conf
)

```

very different interval. if you take pairing into account... look at the graph in the lecture. A lot of variance is explained by the inter-subject variability.

## Chickwiehgt data in R

```{r}
library(datasets)
data(ChickWeight)
library(reshape2)
#define weight gain or loss
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1:2)] <- paste("time", names(wideCW)[-(1:2)], sep = "")
library(dplyr)
wideCW <- mutate(wideCW,
                 gain = time21 - time0)
```

look at lecture plot

violin plot looks nice

```{r}
wideCW14 <- subset(wideCW, Diet %in% c(1,4))
rbind(
        t.test(gain ~ Diet, paired = FALSE, var.equal = TRUE, data = wideCW14)$conf,
        t.test(gain ~ Diet, paired = FALSE, var.equal = FALSE, data = wideCW14)$conf
)

```

both intervals are in negative, suggesting, there is less weight gain in diet 1 compared to diet 4


the confidence interval changes wether the variances are equal or unequal


# a note on unequal variance

> sx <- 15.34
> sy <- 18.23
> df <- ((sx^2/8+sy^2/21)^2)/((sx^2/8)/7+(sy^2/21)/20)
> df <- ((sx^2/8+sy^2/21)^2)/((sx^2/8)^2/7+(sy^2/21)^2/20)

instead of using this stuff, just setting var.equal = FALSE does the trick.

## Comparing other kinds of data

for binomial data, there's lots of ways to compare two groups
- relative risk, risk difference, odds ratio
- Chi-squared tests, normal approximations, exact tests.


------------
# additional class from Mathematical Biostatistics bootcamp 
## conditional probabilities and densities

```{r}
install.packages("rgl")
install.packages("mvtnorm")
#you have to load XQuartz

library(rgl)
library(mvtnorm)
sigma <- matrix(c(8, .25 * 8, .25 *8, 8 ), 2, 2)
xvals <- seq(-10, 10, length = 100)
yvals <- seq(-10, 10, length = 100)
zvals <- apply(expand.grid(xvals, yvals), 1,
               function(w) dmwnorm(w, mean= c(0, 0), sigma = sigma))
persp3d(x = xvals, y = yvals, z = zvals, col = "lightblue")
planes3d(0, 1, 0, -5, col = grey(.8))
```


# Hypothesis Testing

```{r}
library(UsingR)
data(father.son)
t.test(father.son$sheight - father.son$fheight)
```

or add two vectors with parameter paired = TRUE

we reject the null hypothesis : wether the population of son's height was equivalent to the population mean of father's heights.

# Two group testing

```{r}
library(datasets)
data(ChickWeight)
library(reshape2)
#define weight gain or loss
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1:2)] <- paste("time", names(wideCW)[-(1:2)], sep = "")
library(dplyr)
wideCW <- mutate(wideCW,
                 gain = time21 - time0)


wideCW14 <- subset(wideCW, Diet %in% c(1, 4))
t.test(gain ~ Diet, paired = FALSE, var.equal = TRUE,
       data = wideCW14)


```

*whenever you're doing two groups, unless you specify a hypothesized difference in the means, it's going to assume that your interested in testing whether the means are equal under the null hypothesis or different under the alternative.*

t statistic : *how many estimated standard errors* our difference in means is from the hypothesized mean. the estimate, the difference in the average weight gain between the two diets. 

# P valjues

idea : suppose nothing is going on - how unusual is it to see the estimate we got if the null hypothesis is true?

1 - define hypothetical distribution of data summary 
2 - calculate the test statistic(how many standard deviations away from the mean)
3 - compare the two values

the p-value is the probability under the null hypothesis of obtaining evidence as extreme or more extreme than that obtained

if the p-value is small, then either H0 is true and we have observed a rare event or H0 is false


"attained significance level"

for the two sided hypothesis test, double the smaller of the two one sided hypothesis test Pvalues. then you have to double the P values because symmetrically the other side of the bell.



```{r}
pbinom(6, size = 8, prob = .5, lower.tail = FALSE)
```

the probability of being 7 or larger would be one one-sided p value
the probability of being 7 or smaller would be the other one-sided p-value

you take those two one-sided p values, you take the smaller one, and double it

this way you get two sided p-values for exact binomial situations

```{r}
pbinom(6, size = 8, prob = .5)
```

double the smaller one

```{r}
2 * pbinom(6, size = 8, prob = .5, lower.tail = FALSE)
```

under H0 : lambda = 0.05 so that lambda100 = 5
consider Ha : lambda > 0.05

```{r}
ppois(9, 5, lower.tail = FALSE)
```

this is the probability of obtaining 10 or more infections if, in fact, the true rate of infections we've should've seen on a 100 person days at risk is 5. 

it turns out that's a relatively low probability. only 3% chance.

double s

# Swirl lessons

- T confidence intervals
- hypothesis testing
- p values
https://github.com/DataScienceSpecialization/courses/

# T confidence intervals

| So the mean and variance of the standardized normal are fixed and known. Now we'll
| define the t statistic which looks a lot like the Z. It's defined as
| t=(X'-mu)/(s/sqrt(n)). Like the Z statistic, the t is centered around 0. The only
| difference between the two is that the population std deviation, sigma, in Z is
| replaced by the sample standard deviation in the t. So the distribution of the t
| statistic is independent of the population mean and variance. Instead it depends on
| the sample size n.

| As a result, for t distributions, the formula for computing a confidence interval is
| similar to what we did in the last lesson. However, instead of a quantile for a
| normal distribution we use a quantile for a t distribution. So the formula is Est +/-
| t-quantile *std error(Est). The other distinction, which we mentioned before, is that
| we'll use the sample standard deviation when we estimate the standard error of Est.


| As df increases, the t distribution gets more like a standard normal, so it's
| centered around 0. Also, the t assumes that the underlying data are iid Gaussian so
| the statistic (X' - mu)/(s/sqrt(n)) has n-1 degrees of freedom.

| So the t-interval is defined as X' +/- t_(n-1)*s/sqrt(n) where t_(n-1) is the
| relevant quantile. The t interval assumes that the data are iid normal, though
| it is robust to this assumption and works well whenever the distribution of the
| data is roughly symmetric and mound shaped.

| Although it's pretty great, the t interval isn't always applicable. For skewed
| distributions, the spirit of the t interval assumptions (being centered around
| 0) are violated. There are ways of working around this problem (such as taking
| logs or using a different summary like the median).


| For highly discrete data, like binary, intervals other than the t are
| available.

| However, paired observations are often analyzed using the t interval by taking
| differences between the observations. We'll show you what we mean now.

| To clarify, we've defined some variables for you, namely g1 and g2. These are
| two 10-long vectors, respectively holding the results of the 10 patients for
| each of the two drugs. Look at the range of g1 using the R command range.

> range(g1)
[1] -1.6  3.7

| Keep working like that and you'll get there!

  |==================================                                            |  43%
| So g1 values go from -1.6 to 3.7. Now look at the range of g2. We see that the
| ranges of both groups are relatively large.

> range(g2)
[1] -0.1  5.5

| You are really on a roll!

  |===================================                                           |  45%
| Now let's look at the pairwise difference. We can take advantage of R's
| componentwise subtraction of vectors and create the vector of difference by
| subtracting g1 from g2. Do this now and put the result in the variable
| difference.


| Type difference <- g2-g1 at the command prompt.

> difference <- g2 - g1

| All that practice is paying off!

  |====================================                                          |  46%
| Now use the R function mean to find the average of difference.

> mean(difference)
[1] 1.58

| Nice work!

  |=====================================                                         |  47%
| See how much smaller the mean difference in this paired data is compared to the
| group variations?

...

  |======================================                                        |  49%
| Now use the R function sd to find the standard deviation of difference and put
| the result in the variable s.

> s <- sd(difference)

| You nailed it! Good job!

  |=======================================                                       |  50%
| Now recall the formula for finding the t confidence interval, X' +/-
| t_(n-1)*s/sqrt(n). Make the appropriate substitutions to find the 95%
| confidence intervals for the average difference you just computed. We've stored
| that average difference in the variable mn for you to use here. Remember to use
| the R construct c(-1,1) for the +/- portion of the formula and the R function
| qt with .975 and n-1 degrees of freedom for the quantile portion. Our data size
| is 10.


> mn + c(-1, 1)*qt(.975, 9)*s/sqrt(10)
[1] 0.7001142 2.4598858

| That's correct!

  |========================================                                      |  51%
| This says that with probability .95 the average difference of effects (between
| the two drugs) for an individual patient is between .7 and 2.46 additional
| hours of sleep.

| We could also just have used the R function t.test with the argument difference
| to get this result. (You can use the default values for all the other
| arguments.) As with the other R test functions, this returns a lot of
| information. Since all we're interested in at the moment is the confidence
| interval we can pick this off with the construct x$conf.int. Try this now.

> t.test(g2 - g1)$conf.int
[1] 0.7001142 2.4598858
attr(,"conf.level")
[1] 0.95


```{r}
#show 4 different calls to t.test
#display as 4 long array
rbind(
  mn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n),
  as.vector(t.test(difference)$conf.int),
  as.vector(t.test(g2, g1, paired = TRUE)$conf.int),
  as.vector(t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)$conf.int)
)

```





| We now present methods, using t confidence intervals, for comparing independent
| groups.

| Suppose that we want to compare the mean blood pressure between two groups in a
| randomized trial. We'll compare those who received the treatment to those who
| received a placebo. Unlike the sleep study, we cannot use the paired t test
| because the groups are independent and may have different sample sizes.

| So our goal is to find a 95% confidence interval of the difference between two
| population means. Let's represent this difference as mu_y - mu_x. How do we do
| this? Recall our formula X' +/- t_(n-1)*s/sqrt(n).

 First we need a sample mean, but we have two, X' and Y', one from each group.
| It makes sense that we'd have to take their difference (Y'-X') as well, since
| we're looking for a confidence interval that contains the difference mu_y-mu_x.
| Now we need to specify a t quantile. Suppose the groups have different sizes
| n_x and n_y.

 The only term remaining is the standard error which for the single group is
| s/sqrt(n). Let's deal with the numerator first. Our interval will assume (for
| now) a common variance s^2 across the two groups. We'll actually pool variance
| information from the two groups using a weighted sum. (We'll deal with the more
| complicated situation later.)

| We call the variance estimator we use the pooled variance. The formula for it
| requires two variance estimators (in the form of the standard deviation), S_x
| and S_y, one for each group. We multiply each by its respective degrees of
| freedom and divide the sum by the total number of degrees of freedom. This
| weights the respective variances; those coming from bigger samples get more
| weight.

 Now recall we're calculating the standard error term which for the single group
| case was s/sqrt(n). We've got the numerator done, by pooling the sample
| variances. How do we handle the 1/sqrt(n) portion? We can simply add 1/n_x and
| 1/n_y and take the square root of the sum. Then we MULTIPLY this by the sample
| variance to complete the estimate of the standard error.

| Now we'll plug in some numbers from the slides based on an example from
| Rosner's book Fundamentals of Biostatistics, a very good, if heavy, reference
| book. We want to compare blood pressure from two independent groups.

| The first is a group of 8 oral contraceptive users and the second is a group of
| 21 controls. The two means are X'_{oc}=132.86 and X'_{c}=127.44, and the two
| sample standard deviations are s_{oc}= 15.34 and s_{c}= 18.23. Let's first
| compute the numerator of the pooled sample variance by weighting the sum of the
| two by their respective sample sizes. Recall the formula
| (n_x-1)(S_x)^2+(n_y-1)(S_y)^2 and fill in the values to create a variable sp.

| Now to find the 95% confidence interval. Recall our basic formula X' +/-
| t_(n-1)*s/sqrt(n) and all the changes we need to make for working with two
| independent samples. We'll plug in the difference of the sample means for X'
| and our variable ns for the degrees of freedom when finding the t quantile. For
| the standard error, we multiply sp by the square root of the sum 1/n_{oc} +
| 1/n_{c}. The values for this problem are X'_{oc}=132.86 and X'_{c}=127.44,
| n_{oc}=8 and n_{c}=21. Be sure to use the R construct c(-1,1) for the +/-
| portion and the R function qt with the correct percentile and degrees of
| freedom.

> 132.86 - 127.44 + c(-1, 1) * qt(.975, ns) * sp * sqrt(1/8 + 1/21)
[1] -9.521097 20.361097

| Notice that 0 is contained in this 95% interval. That means that you can't rule
| out that the means of the two groups are equal since a difference of 0 is in
| the interval.




| Getting tired? Let's revisit the sleep problem and instead of looking at the
| data as paired over 10 subjects we'll look at it as two independent sets each
| of size 10. Recall the data is stored in the two vectors g1 and g2; we've also
| stored the difference between their means in the variable md.

...

  |=============================================================                 |  78%
| Let's compute the sample pooled variance and store it in the variable sp.
| Recall that this is the sqrt(weighted sums of sample variances/deg of freedom).
| The weight of each is the sample size-1. Use the R function var to compute the
| variances of g1 and g2. The degrees of freedom is 10+10-2 = 18.


sp <- sqrt(9*var(g1)+9*var(g2)/18)

| Not quite! Try again. Or, type info() for more options.

| Type sp <- sqrt((9*var(g1)+9*var(g2))/18) at the command prompt.

> sp <- sqrt((9*var(g1)+9*var(g2))/18)

| Excellent work!

  |==============================================================                |  79%
| Now the last term of the formula, the standard error of the mean difference, is
| simply sp times the square root of the sum 1/10 + 1/10. Find the 95% t
| confidence interval of the mean difference of the two groups g1 and g2.
| Substitute md and sp into the formula you used above.

> md + c(-1, 1) * qt(.975, 18) * sp * sqrt(1/10+1/10)
[1] -0.203874  3.363874

| Keep working like that and you'll get there!

  |===============================================================               |  80%
| We can check this manual calculation against the R function t.test. Since we
| subtracted g1 from g2, be sure to place g2 as your first argument and g1 as
| your second. Also make sure the argument paired is FALSE and var.equal is TRUE.
| We only need the confidence interval so use the construct x$conf.  Do this now.

> t.test(g2 - g1, paired = FALSE, var.equal = TRUE)$conf
[1] 0.7001142 2.4598858
attr(,"conf.level")
[1] 0.95

| Nice try, but that's not exactly what I was hoping for. Try again. Or, type
| info() for more options.

| Type t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf at the command prompt.

> t.test(g2,g1, paired = FALSE, var.equal = TRUE)$conf
[1] -0.203874  3.363874
attr(,"conf.level")
[1] 0.95

| Pretty cool that it matches, right? Note that 0 is again in this 95% interval
| so you can't reject the claim that the two groups are the same. (Recall that
| this is the opposite of what we saw with paired data.) Let's run t.test again,
| this time with paired=TRUE and see how different the result is. Don't specify
| var.equal and look only at the confidence interval.

> t.test(g2, g1, paired = TRUE)$conf
[1] 0.7001142 2.4598858
attr(,"conf.level")
[1] 0.95

| Keep up the great work!

  |=================================================================             |  83%
| Just as we saw when we ran t.test on our vector, difference! See how the
| interval excludes 0? This means the groups when paired have much different
| averages.




| Now let's talk about calculating confidence intervals for two groups which have
| unequal variances. We won't be pooling them as we did before.


| In this case the formula for the interval is similar to what we saw before,
| Y'-X' +/- t_df * SE, where as before Y'-X' represents the difference of the
| sample means. However, the standard error SE and the quantile t_df are
| calculated differently from previous methods. Here SE is the square root of the
| sum of the squared standard errors of the two means, (s_1)^2/n_1 + (s_2)^2/n_2
| .

 When the underlying X and Y data are iid normal and the variances are
| different, the normalized statistic we started this lesson with,
| (X'-mu)/(s/sqrt(n)), doesn't follow a t distribution. However, it can be
| approximated by a t distribution if we set the degrees of freedom
| appropriately.

The formula for the degrees of freedom is a complicated fraction that no one
| remembers.  The numerator is the SQUARE of the sum of the squared standard
| errors of the two sample means. Each has the form s^2/n. The denominator is the
| sum of two terms, one for each group. Each term has the same form. It is the
| standard error of the mean raised to the fourth power divided by the sample
| size-1. More precisely, each term looks like (s^4/n^2)/(n-1). We use this df to
| find the t quantile.

|======================================================================        |  89%
| Here's the formula. You might have to stretch the plot window to get it
| displayed more clearly.

...

  |=======================================================================       |  91%
| Let's plug in the numbers from the blood pressure study to see how this works.
| Recall we have two groups, the first with size 8 and X'_{oc}=132.86 and
| s_{oc}=15.34 and the second with size 21 and X'_{c}=127.44 and s_{c}=18.23.

...

  |========================================================================      |  92%
| Let's compute the degrees of freedom first. Start with the numerator. It's the
| square of the sum of two terms. Each term is of the form s^2/n. Do this now and
| put the result in num. Our numbers were 15.34 with size 8 and 18.23 with size
| 21.

> num <- (15.34^/8 + 18.23^2/21)^2
Error: unexpected '/' in "num <- (15.34^/"
> num <- (15.34^2/8 + 18.23^2/21)^2

| That's the answer I was looking for.

  |=========================================================================     |  93%
| Now the denominator. This is the sum of two terms. Each term has the form
| s^4/n^2/(n-1). These look a little different than the form displayed but
| they're equivalent. Put the result in the variable den. Our numbers were 15.34
| with size 8 and 18.23 with size 21.

> den <- 15.34^4/8^2/7 + 18.23^4/21^2/20

| All that practice is paying off!

  |==========================================================================    |  95%
| Now divide num by den and put the result in mydf.

> mydf <- num/den

| Excellent job!

  |===========================================================================   |  96%
| Now with the R function qt(.975,mydf) compute the 95% t interval. Recall the
| formula. X'_{oc}-X'_{c} +/- t_df * SE. Recall that SE is the square root of the
| sum of the squared standard errors of the two means, (s_1)^2/n_1 + (s_2)^2/n_2
| . Again our numbers are the following. X'_{oc}=132.86 s_{oc}=15.34 and n_{oc}=8
| .  X'_{c}=127.44 s_{c}=18.23 and n_{c}=21.

> 132.86 - 127.44 + c(-1, 1) * qt(.975, mydf) * sqrt(15.34^2/8 + 18.23^2/21)
[1] -8.913327 19.753327

| You are really on a roll!

  |============================================================================  |  97%
| Don't worry about these nasty calculations. R makes things a lot easier. If you
| call t.test with var.equal set to FALSE, then R calculates the degrees of
| freedom for you. You don't have to memorize the formula.

...

  |============================================================================= |  99%
| Congrats! You've concluded this rather t-dious lesson on all things t related -
| statistics, distributions, intervals. Hope you're not too teed off!


# Hypothesis testing






